{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport keras\nimport matplotlib.pyplot as plt\nimport cv2 \nimport os\nimport pickle\n!pip install imutils\nimport imutils\nimport pathlib\nimport math\nimport gc\n\nfrom tqdm import tqdm\nimport keras_tuner as kt\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import StratifiedKFold\n\nDATASET_PATH = r\"../input/neoplasie/T1VOL//\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-20T11:14:06.438628Z","iopub.execute_input":"2021-09-20T11:14:06.438934Z","iopub.status.idle":"2021-09-20T11:14:20.89305Z","shell.execute_reply.started":"2021-09-20T11:14:06.438905Z","shell.execute_reply":"2021-09-20T11:14:20.892177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deskull(path, IMG_SIZE, direct_mode = False):\n    if not direct_mode:\n        img = cv2.imread(path)\n    else:\n        img = cv2.cvtColor(path, cv2.COLOR_BGR2RGB)\n\n    img = cv2.resize(\n                img,\n                dsize=IMG_SIZE,\n                interpolation=cv2.INTER_CUBIC\n        )\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n    # threshold the image, then perform a series of erosions +\n    # dilations to remove any small regions of noise\n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    # find contours in thresholded image, then grab the largest one\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    c = max(cnts, key=cv2.contourArea)\n\n    # find the extreme points\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n    # add contour on the image\n    img_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n\n    # add extreme points\n    img_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\n    img_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\n    img_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\n    img_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n\n    # crop\n    ADD_PIXELS = 0\n    img2 = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n    img_final = cv2.resize(\n        img2,\n        dsize=IMG_SIZE,\n        interpolation=cv2.INTER_CUBIC\n    )\n    return img_final.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:14:20.89475Z","iopub.execute_input":"2021-09-20T11:14:20.895072Z","iopub.status.idle":"2021-09-20T11:14:20.910674Z","shell.execute_reply.started":"2021-09-20T11:14:20.895036Z","shell.execute_reply":"2021-09-20T11:14:20.909811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_dataset(dataframe, indexes=[]):\n    X_train = []\n    Y_train = []\n\n    if len(indexes)>0:\n        source = indexes\n    else:\n        source = dataframe.index\n    \n    for index in source:\n        row = dataframe.iloc[index]\n        current_path = pathlib.PureWindowsPath(row[\"Path\"]).as_posix()\n        X_train.append(DATASET_PATH + current_path)\n        #X_train.append(deskull(DATASET_PATH + current_path,(512,512))/255)\n        if row[\"Class\"] == 'MET':\n            Y_train.append(1)\n        else:\n            Y_train.append(0)\n            \n    return np.array(X_train), np.array(Y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:14:20.91402Z","iopub.execute_input":"2021-09-20T11:14:20.914325Z","iopub.status.idle":"2021-09-20T11:14:20.923362Z","shell.execute_reply.started":"2021-09-20T11:14:20.914289Z","shell.execute_reply":"2021-09-20T11:14:20.922376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe = pd.read_csv(DATASET_PATH + 'dataset.csv')\nfolds = pickle.load(open(DATASET_PATH + 'folds.npy', \"rb\"))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:14:20.926804Z","iopub.execute_input":"2021-09-20T11:14:20.927066Z","iopub.status.idle":"2021-09-20T11:14:20.963121Z","shell.execute_reply.started":"2021-09-20T11:14:20.927034Z","shell.execute_reply":"2021-09-20T11:14:20.962352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SHUFFLE\nfor i in range(0,len(folds)):\n    indices = np.arange(folds[i].shape[0])\n    np.random.shuffle(indices)\n    folds[i] = folds[i][indices]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:14:20.964225Z","iopub.execute_input":"2021-09-20T11:14:20.964576Z","iopub.status.idle":"2021-09-20T11:14:20.97053Z","shell.execute_reply.started":"2021-09-20T11:14:20.964541Z","shell.execute_reply":"2021-09-20T11:14:20.968776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(folds[9])","metadata":{"execution":{"iopub.status.busy":"2021-09-16T20:44:23.433861Z","iopub.execute_input":"2021-09-16T20:44:23.434193Z","iopub.status.idle":"2021-09-16T20:44:23.439368Z","shell.execute_reply.started":"2021-09-16T20:44:23.434164Z","shell.execute_reply":"2021-09-16T20:44:23.438428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = read_dataset(dataframe, [*folds[8], *folds[9], *folds[2], *folds[3], *folds[4], *folds[5], *folds[6], *folds[7]])\nX_val, Y_val = read_dataset(dataframe, [*folds[0],*folds[1]])","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:14:20.971982Z","iopub.execute_input":"2021-09-20T11:14:20.972406Z","iopub.status.idle":"2021-09-20T11:14:21.126878Z","shell.execute_reply.started":"2021-09-20T11:14:20.972368Z","shell.execute_reply":"2021-09-20T11:14:21.126092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VOLSequence(tf.keras.utils.Sequence):\n\n    def __init__(self, x_set, y_set, batch_size, deskull=True, transform=None):\n        self.x, self.y = x_set, y_set\n        self.batch_size = batch_size\n        self.transform = transform\n        self.deskull = deskull\n\n    def __len__(self):\n        return math.ceil(len(self.x) / self.batch_size)\n    \n    def read_img(self, path):\n        img = cv2.imread(path)\n        img = cv2.resize(img, dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n        return img.copy()\n                         \n    def __getitem__(self, idx):\n        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n        self.batch_size]\n        \n        if self.transform is None:\n            if self.deskull:\n                return np.array([\n                    deskull(file_name, (512, 512))\n                       for file_name in batch_x])/255, np.array(batch_y)\n            else:\n                return np.array([\n                    self.read_img(file_name)\n                       for file_name in batch_x])/255, np.array(batch_y)\n        else:\n            if self.deskull:\n                return np.array([\n                    deskull(self.transform(cv2.imread(file_name)), (512, 512), True)\n                       for file_name in batch_x])/255, np.array(batch_y)\n            else:\n                return np.array([\n                    self.transform(self.read_img(file_name))\n                       for file_name in batch_x])/255, np.array(batch_y)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:24:06.773769Z","iopub.execute_input":"2021-09-20T11:24:06.774119Z","iopub.status.idle":"2021-09-20T11:24:06.786328Z","shell.execute_reply.started":"2021-09-20T11:24:06.774069Z","shell.execute_reply":"2021-09-20T11:24:06.785508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_set = VOLSequence(X_train, Y_train, deskull=True, batch_size=32)\nVal_set = VOLSequence(X_val, Y_val, deskull=True, batch_size=32)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:24:08.71081Z","iopub.execute_input":"2021-09-20T11:24:08.711164Z","iopub.status.idle":"2021-09-20T11:24:08.71524Z","shell.execute_reply.started":"2021-09-20T11:24:08.711115Z","shell.execute_reply":"2021-09-20T11:24:08.714389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pre-processing (Crop)","metadata":{}},{"cell_type":"code","source":"#Esempio su una immagine\nIMG_SIZE = (512,512)\nimg = cv2.imread('../input/neoplasie/T1VOL/volGBM/VOL0001_GBM_IDH1MUT.jpg')\nimg = cv2.resize(\n            img,\n            dsize=IMG_SIZE,\n            interpolation=cv2.INTER_CUBIC\n        )\ngray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\ngray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n# threshold the image, then perform a series of erosions +\n# dilations to remove any small regions of noise\nthresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\nthresh = cv2.erode(thresh, None, iterations=2)\nthresh = cv2.dilate(thresh, None, iterations=2)\n\n# find contours in thresholded image, then grab the largest one\ncnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = imutils.grab_contours(cnts)\nc = max(cnts, key=cv2.contourArea)\n\n# find the extreme points\nextLeft = tuple(c[c[:, :, 0].argmin()][0])\nextRight = tuple(c[c[:, :, 0].argmax()][0])\nextTop = tuple(c[c[:, :, 1].argmin()][0])\nextBot = tuple(c[c[:, :, 1].argmax()][0])\n\n# add contour on the image\nimg_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n\n# add extreme points\nimg_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\nimg_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\nimg_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\nimg_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n\n# crop\nADD_PIXELS = 0\nnew_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n","metadata":{"execution":{"iopub.status.busy":"2021-09-15T16:42:55.889067Z","iopub.execute_input":"2021-09-15T16:42:55.889478Z","iopub.status.idle":"2021-09-15T16:42:55.913439Z","shell.execute_reply.started":"2021-09-15T16:42:55.889442Z","shell.execute_reply":"2021-09-15T16:42:55.912329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15,6))\nplt.subplot(141)\nplt.imshow(img)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 1. Get the original image')\nplt.subplot(142)\nplt.imshow(img_cnt)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 2. Find the biggest contour')\nplt.subplot(143)\nplt.imshow(img_pnt)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 3. Find the extreme points')\nplt.subplot(144)\nplt.imshow(new_img)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 4. Crop the image')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T16:42:59.049402Z","iopub.execute_input":"2021-09-15T16:42:59.049768Z","iopub.status.idle":"2021-09-15T16:42:59.3421Z","shell.execute_reply.started":"2021-09-15T16:42:59.049734Z","shell.execute_reply":"2021-09-15T16:42:59.341242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Architettura Rete","metadata":{}},{"cell_type":"code","source":"# VGG16\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Flatten, GlobalAveragePooling2D, Dropout\n\ndef get_model():\n    # load model without classifier layers\n    base_model = VGG16(include_top=False, input_shape=(512, 512, 3))\n    base_model.trainable = False\n\n    inputs = keras.Input(shape=(512, 512, 3))\n    #x = preprocess_input(inputs)\n    base_model = base_model(inputs, training=False)\n\n    # add new classifier layers\n    flat1 = Flatten()(base_model)\n    out = Dropout(0.5)(flat1)\n    output = Dense(1, activation='sigmoid')(out)\n    # define new model\n    model = Model(inputs=[inputs], outputs=[output])\n    return model\n\n#Metriche\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:14:41.825959Z","iopub.execute_input":"2021-09-20T11:14:41.826334Z","iopub.status.idle":"2021-09-20T11:14:41.836377Z","shell.execute_reply.started":"2021-09-20T11:14:41.826303Z","shell.execute_reply":"2021-09-20T11:14:41.835491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nkeras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:14:46.574154Z","iopub.execute_input":"2021-09-20T11:14:46.574475Z","iopub.status.idle":"2021-09-20T11:14:50.263034Z","shell.execute_reply.started":"2021-09-20T11:14:46.574445Z","shell.execute_reply":"2021-09-20T11:14:50.262169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ricerca iperparametri","metadata":{}},{"cell_type":"code","source":"def build_model(hp):\n    # load model without classifier layers\n    base_model = VGG16(include_top=False, input_shape=(512, 512, 3))\n    base_model.trainable = False\n\n    inputs = keras.Input(shape=(512, 512, 3))\n    x = preprocess_input(inputs)\n    base_model = base_model(x, training=False)\n\n    flat1 = Flatten()(base_model)\n    out = Dropout(0.5)(flat1)\n    output = Dense(1, activation='sigmoid')(out)\n    model = Model(inputs=[inputs], outputs=[output])\n    \n    lr = hp.Float(\n        'learning_rate',\n        min_value=1e-5,\n        max_value=1e-2,\n        sampling='LOG',\n        default=1e-3\n    )\n    #keras.optimizers.RMSprop(lr=1e-4)\n    model.compile(optimizer=keras.optimizers.Adam(lr), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),metrics=keras.metrics.BinaryAccuracy())\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-17T09:37:58.937474Z","iopub.execute_input":"2021-09-17T09:37:58.937967Z","iopub.status.idle":"2021-09-17T09:37:58.948006Z","shell.execute_reply.started":"2021-09-17T09:37:58.937928Z","shell.execute_reply":"2021-09-17T09:37:58.946476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner = kt.RandomSearch(\n    build_model,\n    objective='val_loss',\n    max_trials=5)\n\ntuner.search(training_set, epochs=5, validation_data=valid_set)\nbest_model = tuner.get_best_models()[0]","metadata":{"execution":{"iopub.status.busy":"2021-07-26T09:10:19.428212Z","iopub.execute_input":"2021-07-26T09:10:19.428538Z","iopub.status.idle":"2021-07-26T09:19:40.758353Z","shell.execute_reply.started":"2021-07-26T09:10:19.428509Z","shell.execute_reply":"2021-07-26T09:19:40.757457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.results_summary()\nmodel = best_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Addestramento","metadata":{}},{"cell_type":"code","source":"callbacks = []\nrunPath = './models/'\ncallbacks.append(keras.callbacks.ModelCheckpoint(runPath + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only = False, mode='min', save_freq='epoch'))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()\nmodel.compile(optimizer=keras.optimizers.Adam(lr=0.00005), loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),metrics=['binary_accuracy',f1_m,precision_m, recall_m])\nhistory = model.fit(Train_set, epochs=25, validation_data=Val_set, callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T09:39:06.923734Z","iopub.execute_input":"2021-09-17T09:39:06.924271Z","iopub.status.idle":"2021-09-17T09:39:07.342346Z","shell.execute_reply.started":"2021-09-17T09:39:06.924235Z","shell.execute_reply":"2021-09-17T09:39:07.341173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sn\n\nlabels = [\"GBM (0)\",\"MET (1)\"]\n\n#Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\nY_test = Val_set.y\ny_pred = model.predict(Val_set)\nrounded_pred = np.round(abs(y_pred))\nprint(classification_report(Y_test, rounded_pred, target_names=labels))\n\nconfusion_matrix = confusion_matrix(Y_test, rounded_pred)\n\nsn.set(font_scale = 1.4)\nsn.heatmap(confusion_matrix, annot=True, annot_kws={\"size\":16})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:44:59.704446Z","iopub.execute_input":"2021-09-20T11:44:59.704789Z","iopub.status.idle":"2021-09-20T11:45:05.570813Z","shell.execute_reply.started":"2021-09-20T11:44:59.704756Z","shell.execute_reply":"2021-09-20T11:45:05.57006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot a video della training history\nplt.figure(figsize=(20, 10))\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\nplt.figure(figsize=(20, 10))\n# summarize history for loss\nplt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_binary_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-15T15:56:35.660075Z","iopub.execute_input":"2021-09-15T15:56:35.660509Z","iopub.status.idle":"2021-09-15T15:56:36.044505Z","shell.execute_reply.started":"2021-09-15T15:56:35.660466Z","shell.execute_reply":"2021-09-15T15:56:36.043638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = np.load(\"./best_history_VOL.npy\", allow_pickle = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T21:43:10.348762Z","iopub.execute_input":"2021-09-16T21:43:10.349079Z","iopub.status.idle":"2021-09-16T21:43:10.35315Z","shell.execute_reply.started":"2021-09-16T21:43:10.349051Z","shell.execute_reply":"2021-09-16T21:43:10.352333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SALVATAGGIO MODELLO:\nmodel.save('./best_model_VOL.h5')\n\n#Salvo i dati \"storici\" completi dell'apprendimento\nwith open('./best_history_VOL.npy', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T21:17:50.780833Z","iopub.execute_input":"2021-09-16T21:17:50.781177Z","iopub.status.idle":"2021-09-16T21:17:50.891306Z","shell.execute_reply.started":"2021-09-16T21:17:50.781146Z","shell.execute_reply":"2021-09-16T21:17:50.890419Z"},"trusted":true},"execution_count":null,"outputs":[]}]}