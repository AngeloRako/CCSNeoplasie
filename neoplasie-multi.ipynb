{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport keras\nimport matplotlib.pyplot as plt\nimport cv2 \nimport os\nimport pickle\nimport glob\nimport math\nimport random\n!pip install imutils\nimport imutils\nimport pickle\nimport gc\n\nfrom tqdm import tqdm\nimport keras_tuner as kt\nfrom tensorflow.keras.utils import Sequence\nimport tensorflow.keras.backend as K\nimport pathlib\nfrom sklearn.model_selection import StratifiedKFold\n\nDATASET_PATH = r\"../input/neoplasie/multimodalMRI/\"\nCATEGORIES = [\"ADC\",\"DWI\",\"FLAIR\",\"GRE\",\"MDC\",\"T1W\"]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-20T11:00:13.179759Z","iopub.execute_input":"2021-09-20T11:00:13.180133Z","iopub.status.idle":"2021-09-20T11:00:28.275194Z","shell.execute_reply.started":"2021-09-20T11:00:13.180094Z","shell.execute_reply":"2021-09-20T11:00:28.274256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def deskull(path, IMG_SIZE, direct_mode = False):\n    if not direct_mode:\n        img = cv2.imread(path)\n    else:\n        img = cv2.cvtColor(path, cv2.COLOR_BGR2RGB)\n\n    img = cv2.resize(\n                img,\n                dsize=IMG_SIZE,\n                interpolation=cv2.INTER_CUBIC\n        )\n    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n    # threshold the image, then perform a series of erosions +\n    # dilations to remove any small regions of noise\n    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n    thresh = cv2.erode(thresh, None, iterations=2)\n    thresh = cv2.dilate(thresh, None, iterations=2)\n\n    # find contours in thresholded image, then grab the largest one\n    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cnts = imutils.grab_contours(cnts)\n    c = max(cnts, key=cv2.contourArea)\n\n    # find the extreme points\n    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n    extRight = tuple(c[c[:, :, 0].argmax()][0])\n    extTop = tuple(c[c[:, :, 1].argmin()][0])\n    extBot = tuple(c[c[:, :, 1].argmax()][0])\n\n    # add contour on the image\n    img_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n\n    # add extreme points\n    img_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\n    img_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\n    img_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\n    img_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n\n    # crop\n    ADD_PIXELS = 0\n    img2 = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n    img_final = cv2.resize(\n        img2,\n        dsize=IMG_SIZE,\n        interpolation=cv2.INTER_CUBIC\n    )\n    return img_final.copy()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:00:28.276881Z","iopub.execute_input":"2021-09-20T11:00:28.277265Z","iopub.status.idle":"2021-09-20T11:00:28.293586Z","shell.execute_reply.started":"2021-09-20T11:00:28.277232Z","shell.execute_reply":"2021-09-20T11:00:28.292778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_dataset(dataframe, indexes=[], perform_deskull=True):\n    X_train = []\n    Y_train = []\n    for category in CATEGORIES:\n        X_train.append([])\n\n    if len(indexes)>0:\n        source = indexes\n    else:\n        source = dataframe.index\n    \n    for index in source:\n        row = dataframe.iloc[index]\n        temp = []\n        for category in CATEGORIES:\n            cat_index = CATEGORIES.index(category)\n            current_path = pathlib.PureWindowsPath(row[category]).as_posix()\n            if perform_deskull:\n                X_train[cat_index].append(deskull(DATASET_PATH + current_path,(224,224))/255)\n            else:\n                image = cv2.imread(DATASET_PATH + current_path)\n                image = cv2.resize(image, dsize=(224, 224), interpolation=cv2.INTER_CUBIC)\n                X_train[cat_index].append(image/255)\n        if row[\"Class\"] == 'MET':\n            Y_train.append(1)\n        else:\n            Y_train.append(0)\n\n    for i in range(0,len(CATEGORIES)):\n        X_train[i] = np.array(X_train[i])\n    return np.array(X_train), np.array(Y_train)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:00:28.295631Z","iopub.execute_input":"2021-09-20T11:00:28.295985Z","iopub.status.idle":"2021-09-20T11:00:28.30722Z","shell.execute_reply.started":"2021-09-20T11:00:28.29595Z","shell.execute_reply":"2021-09-20T11:00:28.306179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframe = pd.read_csv(DATASET_PATH + 'dataset.csv')\nfolds = pickle.load(open(DATASET_PATH + 'folds.npy', \"rb\"))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:00:28.308898Z","iopub.execute_input":"2021-09-20T11:00:28.309342Z","iopub.status.idle":"2021-09-20T11:00:28.340174Z","shell.execute_reply.started":"2021-09-20T11:00:28.309306Z","shell.execute_reply":"2021-09-20T11:00:28.339343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SHUFFLE\nfor i in range(0,len(folds)):\n    indices = np.arange(folds[i].shape[0])\n    np.random.shuffle(indices)\n    folds[i] = folds[i][indices]","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:34:37.746367Z","iopub.execute_input":"2021-09-17T08:34:37.746718Z","iopub.status.idle":"2021-09-17T08:34:37.751747Z","shell.execute_reply.started":"2021-09-17T08:34:37.746682Z","shell.execute_reply":"2021-09-17T08:34:37.750693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, Y_train = read_dataset(dataframe, [*folds[8], *folds[9], *folds[2], *folds[3], *folds[4], *folds[5], *folds[6], *folds[7]], perform_deskull=True) #Fold 2 to 9 //80%\nX_val, Y_val = read_dataset(dataframe, [*folds[0],*folds[1]], perform_deskull=True) #Fold 0,1 //20%","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:02:38.265066Z","iopub.execute_input":"2021-09-20T11:02:38.265414Z","iopub.status.idle":"2021-09-20T11:02:49.583283Z","shell.execute_reply.started":"2021-09-20T11:02:38.265381Z","shell.execute_reply":"2021-09-20T11:02:49.582357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. # Architettura Rete","metadata":{}},{"cell_type":"code","source":"import tensorflow\nimport keras\nfrom keras import Input, Model\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, Flatten, Concatenate\nfrom keras.activations import relu\nfrom keras import backend as K\n\n#Modello\ndef get_model():\n    # Multiple inputs\n    in1 = Input(shape=(224,224,3))\n    in2 = Input(shape=(224,224,3))\n    in3 = Input(shape=(224,224,3))\n    in4 = Input(shape=(224,224,3))\n    in5 = Input(shape=(224,224,3))\n    in6 = Input(shape=(224,224,3))\n\n    # CNN output\n    cnn = DenseNet121(include_top=False)\n    cnn.trainable = False\n\n    out1 = cnn(in1)\n    out2 = cnn(in2)\n    out3 = cnn(in3)\n    out4 = cnn(in4)\n    out5 = cnn(in5)\n    out6 = cnn(in6)\n\n    # Flattening the output for the dense layer\n    fout1 = Flatten()(out1)\n    fout2 = Flatten()(out2)\n    fout3 = Flatten()(out3)\n    fout4 = Flatten()(out4)\n    fout5 = Flatten()(out5)\n    fout6 = Flatten()(out6)\n\n    # Concatenating the final output\n    out = Concatenate(axis=-1)([fout1, fout2, fout3, fout4, fout5, fout6])\n    out = Flatten()(out)\n\n    # Getting the dense output\n    dense = Dense(32, activation='relu')(out)\n    dense = Dense(1, activation='sigmoid')(dense)\n\n    # Creating the model\n    model = Model(inputs=[in1,in2,in3,in4,in5,in6], outputs=dense)\n    return model\n\n#Metriche\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:01:15.008009Z","iopub.execute_input":"2021-09-20T11:01:15.00833Z","iopub.status.idle":"2021-09-20T11:01:15.023162Z","shell.execute_reply.started":"2021-09-20T11:01:15.0083Z","shell.execute_reply":"2021-09-20T11:01:15.022075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keras.utils.plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2021-09-15T11:27:20.658348Z","iopub.execute_input":"2021-09-15T11:27:20.658682Z","iopub.status.idle":"2021-09-15T11:27:21.25714Z","shell.execute_reply.started":"2021-09-15T11:27:20.658636Z","shell.execute_reply":"2021-09-15T11:27:21.256274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Addestramento","metadata":{}},{"cell_type":"code","source":"#Optional Callback: save checkpoints\ncallbacks = []\nrunPath = './models/'\n#callbacks.append(keras.callbacks.ModelCheckpoint(runPath + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only = False, mode='min', save_freq='epoch'))","metadata":{"execution":{"iopub.status.busy":"2021-09-20T10:10:16.904337Z","iopub.execute_input":"2021-09-20T10:10:16.904695Z","iopub.status.idle":"2021-09-20T10:10:16.90979Z","shell.execute_reply.started":"2021-09-20T10:10:16.904652Z","shell.execute_reply":"2021-09-20T10:10:16.908515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#keras.optimizers.RMSprop(lr=1e-4)\nmodel = get_model()\nmodel.compile(optimizer=keras.optimizers.Adam(lr=0.00001), loss=tf.keras.losses.BinaryCrossentropy(),metrics=['binary_accuracy',f1_m,precision_m, recall_m])\nhistory = model.fit([X_train[0], X_train[1], X_train[2], X_train[3], X_train[4], X_train[5]], Y_train, epochs=10, validation_data= ([X_val[0], X_val[1], X_val[2], X_val[3], X_val[4], X_val[5]], Y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\nimport seaborn as sn\n\nlabels = [\"GBM (0)\",\"MET (1)\"]\n\n#Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\nY_test = Y_val\ny_pred = model.predict([X_val[0], X_val[1], X_val[2], X_val[3], X_val[4], X_val[5]])\nrounded_pred = np.round(abs(y_pred))\nprint(classification_report(Y_test, rounded_pred, target_names=labels))\n\nconfusion_matrix = confusion_matrix(Y_test, rounded_pred)\n\nsn.set(font_scale = 1.4)\nsn.heatmap(confusion_matrix, annot=True, annot_kws={\"size\":16})\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:03:02.222566Z","iopub.execute_input":"2021-09-20T11:03:02.222932Z","iopub.status.idle":"2021-09-20T11:03:03.497699Z","shell.execute_reply.started":"2021-09-20T11:03:02.222896Z","shell.execute_reply":"2021-09-20T11:03:03.496888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model(\"../input/neoplasiemodels/MULTI/VGG16 MULTI 80-20/best_model.h5\", custom_objects={\"recall_m\": recall_m, \"precision_m\": precision_m, \"f1_m\": f1_m})","metadata":{"execution":{"iopub.status.busy":"2021-09-20T11:01:20.594552Z","iopub.execute_input":"2021-09-20T11:01:20.594901Z","iopub.status.idle":"2021-09-20T11:01:24.124623Z","shell.execute_reply.started":"2021-09-20T11:01:20.594867Z","shell.execute_reply":"2021-09-20T11:01:24.123436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, X, Y, index):\n    prediction = model.predict([X[0][index:index+1], X[1][index:index+1], X[2][index:index+1], X[3][index:index+1], X[4][index:index+1], X[5][index:index+1]])\n    gt = Y[index]\n    return prediction, gt","metadata":{"execution":{"iopub.status.busy":"2021-09-20T10:01:50.678992Z","iopub.execute_input":"2021-09-20T10:01:50.679275Z","iopub.status.idle":"2021-09-20T10:01:50.686006Z","shell.execute_reply.started":"2021-09-20T10:01:50.679246Z","shell.execute_reply":"2021-09-20T10:01:50.684945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(model,X_val,Y_val,0)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T10:02:04.849946Z","iopub.execute_input":"2021-09-20T10:02:04.850445Z","iopub.status.idle":"2021-09-20T10:02:06.245006Z","shell.execute_reply.started":"2021-09-20T10:02:04.850412Z","shell.execute_reply":"2021-09-20T10:02:06.244189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nplt.imshow(X_train[0][0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot a video della training history\nplt.figure(figsize=(20, 10))\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\nplt.figure(figsize=(20, 10))\n# summarize history for loss\nplt.plot(history.history['binary_accuracy'])\nplt.plot(history.history['val_binary_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:44:00.011104Z","iopub.execute_input":"2021-09-17T08:44:00.011509Z","iopub.status.idle":"2021-09-17T08:44:00.470279Z","shell.execute_reply.started":"2021-09-17T08:44:00.011471Z","shell.execute_reply":"2021-09-17T08:44:00.469277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# SALVATAGGIO MODELLO:\nmodel.save('./best_model.h5')\n\n#Salvo i dati \"storici\" completi dell'apprendimento\nwith open('./best_history.npy', 'wb') as file_pi:\n        pickle.dump(history.history, file_pi)","metadata":{"execution":{"iopub.status.busy":"2021-09-17T08:41:54.571588Z","iopub.execute_input":"2021-09-17T08:41:54.572101Z","iopub.status.idle":"2021-09-17T08:41:54.804871Z","shell.execute_reply.started":"2021-09-17T08:41:54.572056Z","shell.execute_reply":"2021-09-17T08:41:54.803942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(X_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}